{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "\n",
    "\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import sys\n",
    "import os\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('bad_words.txt')\n",
    "bad_words_vocabulary=f.read()\n",
    "bad_words_vocabulary=bad_words_vocabulary.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_scan(text):\n",
    "    return lazy_text_scan(text)\n",
    "def audio_scan(file_name):\n",
    "    text=audio_to_txt(audio_name)\n",
    "    return text_scan(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_txt(text):\n",
    "    words_in_text=word_tokenize(text, language=\"russian\")\n",
    "    stop_words=stopwords.words(\"russian\")\n",
    "    stop_words+=['.',',',';',':','!','?','','#','-','``',\"''\"]\n",
    "    filtered_words=[]\n",
    "    for token in words_in_text:\n",
    "        if token not in stop_words:\n",
    "            filtered_words.append(token)\n",
    "            \n",
    "    \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    for i in range(len(filtered_words)):\n",
    "        filtered_words[i] = morph.parse(filtered_words[i])[0].normal_form\n",
    "    end_txt=''\n",
    "    for word in filtered_words:\n",
    "        end_txt=end_txt+' '+word\n",
    "    return(end_txt)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты',\n",
       " 'к',\n",
       " 'у',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'по',\n",
       " 'только',\n",
       " 'ее',\n",
       " 'мне',\n",
       " 'было',\n",
       " 'вот',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'еще',\n",
       " 'нет',\n",
       " 'о',\n",
       " 'из',\n",
       " 'ему',\n",
       " 'теперь',\n",
       " 'когда',\n",
       " 'даже',\n",
       " 'ну',\n",
       " 'вдруг',\n",
       " 'ли',\n",
       " 'если',\n",
       " 'уже',\n",
       " 'или',\n",
       " 'ни',\n",
       " 'быть',\n",
       " 'был',\n",
       " 'него',\n",
       " 'до',\n",
       " 'вас',\n",
       " 'нибудь',\n",
       " 'опять',\n",
       " 'уж',\n",
       " 'вам',\n",
       " 'ведь',\n",
       " 'там',\n",
       " 'потом',\n",
       " 'себя',\n",
       " 'ничего',\n",
       " 'ей',\n",
       " 'может',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'где',\n",
       " 'есть',\n",
       " 'надо',\n",
       " 'ней',\n",
       " 'для',\n",
       " 'мы',\n",
       " 'тебя',\n",
       " 'их',\n",
       " 'чем',\n",
       " 'была',\n",
       " 'сам',\n",
       " 'чтоб',\n",
       " 'без',\n",
       " 'будто',\n",
       " 'чего',\n",
       " 'раз',\n",
       " 'тоже',\n",
       " 'себе',\n",
       " 'под',\n",
       " 'будет',\n",
       " 'ж',\n",
       " 'тогда',\n",
       " 'кто',\n",
       " 'этот',\n",
       " 'того',\n",
       " 'потому',\n",
       " 'этого',\n",
       " 'какой',\n",
       " 'совсем',\n",
       " 'ним',\n",
       " 'здесь',\n",
       " 'этом',\n",
       " 'один',\n",
       " 'почти',\n",
       " 'мой',\n",
       " 'тем',\n",
       " 'чтобы',\n",
       " 'нее',\n",
       " 'сейчас',\n",
       " 'были',\n",
       " 'куда',\n",
       " 'зачем',\n",
       " 'всех',\n",
       " 'никогда',\n",
       " 'можно',\n",
       " 'при',\n",
       " 'наконец',\n",
       " 'два',\n",
       " 'об',\n",
       " 'другой',\n",
       " 'хоть',\n",
       " 'после',\n",
       " 'над',\n",
       " 'больше',\n",
       " 'тот',\n",
       " 'через',\n",
       " 'эти',\n",
       " 'нас',\n",
       " 'про',\n",
       " 'всего',\n",
       " 'них',\n",
       " 'какая',\n",
       " 'много',\n",
       " 'разве',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'моя',\n",
       " 'впрочем',\n",
       " 'хорошо',\n",
       " 'свою',\n",
       " 'этой',\n",
       " 'перед',\n",
       " 'иногда',\n",
       " 'лучше',\n",
       " 'чуть',\n",
       " 'том',\n",
       " 'нельзя',\n",
       " 'такой',\n",
       " 'им',\n",
       " 'более',\n",
       " 'всегда',\n",
       " 'конечно',\n",
       " 'всю',\n",
       " 'между']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_text_scan(text):\n",
    "    x=text.split('\\n')\n",
    "    text=''\n",
    "    for line in x:\n",
    "        text+=line + ' '\n",
    "    text = normalize_txt(text)\n",
    "    array_words=text.split(' ')\n",
    "    agressiv_flag = 0\n",
    "    for word in array_words:\n",
    "        if word in bad_words_vocabulary:\n",
    "            agressiv_flag=1\n",
    "            break\n",
    "    \n",
    "    if agressiv_flag==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_txt(file_name):\n",
    "    \n",
    "    os.system(f'ffmpeg -i {file_name} out.wav')\n",
    "    \n",
    "    model = Model(\"model\")\n",
    "\n",
    "    # Large vocabulary free form recognition\n",
    "    rec = KaldiRecognizer(model, 16000)\n",
    "\n",
    "    wf = wave.open('out.wav', \"rb\")\n",
    "\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        print (\"Audio file must be WAV format mono PCM.\")\n",
    "        exit (1)\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    transcript=''\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            json_dict = json.loads(rec.Result())\n",
    "            transcript += json_dict['text']\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "    os.system(f'rm out.wav')\n",
    "    print(transcript)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
