{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serial-mediterranean",
   "metadata": {},
   "source": [
    "10000 сообщений нормировались за 20 минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorrect-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaning_message\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors  \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confirmed-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняет модель на диске\n",
    "def save_model(model,name='model'):\n",
    "    model.wv.save_word2vec_format(f'{name}.bin', binary=True)\n",
    "\n",
    "#загружает модель с диска\n",
    "def download_model(name='model'):\n",
    "    model = KeyedVectors.load_word2vec_format('{name}.bin', binary=True)\n",
    "    \n",
    "\n",
    "def create_model(data):\n",
    "    start_time = time.time()\n",
    "    model = Word2Vec(data, min_count = 0,size=50, workers=cpu_count())\n",
    "    print(f\"на создание модели потребовалось {time.time() - start_time} секунд\")\n",
    "    return (model)\n",
    "\n",
    "\n",
    "def synonyms_word(word,model):\n",
    "    synonyms=model.wv.most_similar(positive=[f\"{word}\"])\n",
    "    return (synonyms)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#нормирует документ сохраняя результат в новом  \n",
    "def raw_to_normal(start_name,finish_name):\n",
    "    start_time = time.time()\n",
    "    file_start=open(f'{start_name}.txt','r')\n",
    "    total_lines=0\n",
    "    \n",
    "    for line in file_start:\n",
    "        total_lines+=1\n",
    "    file_start.close()\n",
    "    #total_lines=1000#для теста\n",
    "    count_lines=0\n",
    "    \n",
    "    file_start=open(f'{start_name}.txt','r')\n",
    "    file_finish=open(f'{finish_name}.txt','w')\n",
    "    for line in file_start:\n",
    "        file_finish.write(scaning_message.normalize_txt(line)+'\\n')\n",
    "        count_lines+=1\n",
    "        \n",
    "        scaning_message.progress(count_lines,total_lines,\"нормировано\")\n",
    "        \n",
    "        if count_lines== total_lines:\n",
    "            break\n",
    "    file_start.close()\n",
    "    file_finish.close()\n",
    "    print(f\"нормировка заняла {time.time() - start_time} секунд\")\n",
    "\n",
    "def get_normalized_data(name_file):\n",
    "    data=[]\n",
    "    file=open(f'{name_file}.txt','r')\n",
    "    for line in file:\n",
    "        data.append(line)\n",
    "    file.close()\n",
    "    for i in range(len(data)):\n",
    "        data[i]=data[i].split(' ')\n",
    "        data[i][-1]=data[i][-1][:len(data[i][-1])-1]\n",
    "        for j in range (len(data[i])):\n",
    "            if 'id' in data[i][j]:\n",
    "                data[i][j]=''\n",
    "        if ' ' in data[i]:\n",
    "            data[i].remove(' ')\n",
    "        elif '...' in data[i]:\n",
    "            data[i].remove('...')\n",
    "        elif '' in data[i]:\n",
    "            data[i].remove('')\n",
    "        elif ',' in data[i]:\n",
    "            data[i].remove(',')\n",
    "        elif ':' in data[i]:\n",
    "            data[i].remove(':')\n",
    "        elif '-' in data[i]:\n",
    "            data[i].remove('-')\n",
    "        elif ']' in data[i]:\n",
    "            data[i].remove(']')\n",
    "        elif '[' in data[i]:\n",
    "            data[i].remove('[')\n",
    "        \n",
    "    return (data)\n",
    "\n",
    "def get_vector(word,model):\n",
    "    return model[word]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "declared-cherry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нормировка заняла 19065.07349538803 секунд 100.0% ...нормировано\n"
     ]
    }
   ],
   "source": [
    "raw_to_normal('more_coments','norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-magic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=get_normalized_data('norm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plastic-thailand",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "на создание модели потребовалось 56.51369905471802 секунд\n"
     ]
    }
   ],
   "source": [
    "model=create_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yellow-education",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кошка', 0.8982638716697693),\n",
       " ('пёс', 0.8309276103973389),\n",
       " ('котёнок', 0.8248428702354431),\n",
       " ('собачка', 0.7985167503356934),\n",
       " ('собака', 0.7932366728782654),\n",
       " ('хозяйка', 0.7278547883033752),\n",
       " ('хася', 0.7276586890220642),\n",
       " ('котик', 0.718923032283783),\n",
       " ('съедение', 0.6872754693031311),\n",
       " ('ребёночек', 0.6872730255126953)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_word('кот',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enabling-enemy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08659966  1.9326174  -0.38252205  0.9002273   0.32290027 -0.36020696\n",
      " -1.222435    1.4398873  -1.9707593  -1.2629893   1.4483807  -1.0553977\n",
      "  0.8041711   1.4306101   1.1315747  -1.6722149   2.204809    0.68184084\n",
      "  0.625223    0.5985732  -1.1109047  -0.5927945   0.35397062  0.38531822\n",
      "  2.9079354  -0.85332316 -3.361672    3.542375   -0.0654007  -0.02130559\n",
      "  1.0551704   0.6429949  -2.0501316   0.03897918 -0.45482633  0.62069815\n",
      " -0.55301285 -0.46896544  1.5235717  -1.3742055   0.7973823  -0.82711196\n",
      " -1.5434997   0.65282184 -0.6307232  -0.71468544  1.0442744  -0.28842247\n",
      "  1.2780718  -1.6499374 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-bb3865d35514>:59: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  return model[word]\n"
     ]
    }
   ],
   "source": [
    "print(get_vector('кот',model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-frame",
   "metadata": {},
   "source": [
    "# #создание базовой обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informed-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('bad_words.txt','r')\n",
    "x=[]\n",
    "for line in file:\n",
    "    x.append(line)\n",
    "bad_words=x[0].split(', ')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frequent-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Создание файлов с плохими словами и без"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "imported-toner",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8d6b09884ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgood_phrases1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mbad_phrases1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgood_phrases1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "count_bad=0\n",
    "all_phrases=open('norm1.txt','r')\n",
    "bad_phrases1= open('bad_phrases1.txt','w')\n",
    "good_phrases1= open('good_phrases1.txt','w')\n",
    "text=[]\n",
    "for line in all_phrases:\n",
    "    text.append(line)\n",
    "for i in range(len(data)):\n",
    "    flag=0\n",
    "    for word in data[i]:\n",
    "        if word in bad_words:\n",
    "            flag=1\n",
    "            count_bad+=1\n",
    "            bad_phrases1.write(text[i])\n",
    "            break\n",
    "    if flag==0:\n",
    "        \n",
    "        good_phrases1.write(text[i])\n",
    "bad_phrases1.close()\n",
    "good_phrases1.close()\n",
    "            \n",
    "print(count_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conventional-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разметка\n",
    "#Первый нейрон отчечает за нормальные аудиозаписи, второй за оскорбительные\n",
    "count_bad=0\n",
    "y_data=[]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    flag=0\n",
    "    for word in data[i]:\n",
    "        if word in bad_words:\n",
    "            flag=1\n",
    "            count_bad+=1\n",
    "            y_data.append(np.array([0,1]))\n",
    "            break\n",
    "    if flag==0:\n",
    "        y_data.append(np.array([1,0]))\n",
    "    \n",
    "y_data=np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parliamentary-violin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-bb3865d35514>:59: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  return model[word]\n"
     ]
    }
   ],
   "source": [
    "max_words=100\n",
    "z= np.zeros(50)\n",
    "x_data=data[:50000]\n",
    "for n in range(len(x_data)):\n",
    "    for n_word in range(len(x_data[n])):\n",
    "        try:\n",
    "            x_data[n][n_word]=get_vector(x_data[n][n_word],model)\n",
    "        except:\n",
    "            x_data[n][n_word]=z\n",
    "\n",
    "        \n",
    "        \n",
    "    if len(x_data[n])>max_words:\n",
    "        x_data[n]=x_data[n][:max_words]\n",
    "    else:\n",
    "        while len(x_data[n])<max_words:\n",
    "            x_data[n].insert(0,z)\n",
    "        \n",
    "    \n",
    "    x_data[n]=np.array(x_data[n])\n",
    "    \n",
    "x_data=np.array(x_data)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "annoying-medline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "motivated-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3541\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(x_data)):\n",
    "        if y_data[i][1]==1:\n",
    "            count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excited-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "X.append(x_data[0])\n",
    "Y.append(y_data[0])\n",
    "for i in range (len(x_data)-1):\n",
    "    if y_data[i][0]!=Y[len(Y)-1][0]:\n",
    "        X.append(x_data[i])\n",
    "        Y.append(y_data[i])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "junior-myrtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6187"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bridal-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, SimpleRNN, Input, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "subsequent-administration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100, 50)           2550      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 50)           20200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 43,482\n",
      "Trainable params: 43,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_model = Sequential()\n",
    "network_model.add(Input((100, 50)))\n",
    "network_model.add(Dense(units=50, activation='linear'))\n",
    "network_model.add(LSTM(50, return_sequences=True))\n",
    "network_model.add(LSTM(50))\n",
    "network_model.add(Dense(units=10, activation='linear'))\n",
    "network_model.add(Dense(2, activation='softmax'))\n",
    "network_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "reflected-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "secondary-compatibility",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "174/174 [==============================] - 14s 53ms/step - loss: 0.5980 - accuracy: 0.6687 - val_loss: 0.4166 - val_accuracy: 0.7964\n",
      "Epoch 2/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.3984 - accuracy: 0.8291 - val_loss: 0.3968 - val_accuracy: 0.8401\n",
      "Epoch 3/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.3178 - accuracy: 0.8629 - val_loss: 0.3535 - val_accuracy: 0.8675\n",
      "Epoch 4/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.2783 - accuracy: 0.8842 - val_loss: 0.3203 - val_accuracy: 0.8627\n",
      "Epoch 5/30\n",
      "174/174 [==============================] - 8s 46ms/step - loss: 0.2379 - accuracy: 0.8996 - val_loss: 0.2977 - val_accuracy: 0.8918\n",
      "Epoch 6/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.1848 - accuracy: 0.9233 - val_loss: 0.2837 - val_accuracy: 0.8821\n",
      "Epoch 7/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.1946 - accuracy: 0.9214 - val_loss: 0.3154 - val_accuracy: 0.8675\n",
      "Epoch 8/30\n",
      "174/174 [==============================] - 8s 46ms/step - loss: 0.1464 - accuracy: 0.9385 - val_loss: 0.3369 - val_accuracy: 0.8708\n",
      "Epoch 9/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.1195 - accuracy: 0.9530 - val_loss: 0.3257 - val_accuracy: 0.8901\n",
      "Epoch 10/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0898 - accuracy: 0.9678 - val_loss: 0.3414 - val_accuracy: 0.8821\n",
      "Epoch 11/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0700 - accuracy: 0.9728 - val_loss: 0.3559 - val_accuracy: 0.8772\n",
      "Epoch 12/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 0.4693 - val_accuracy: 0.8901\n",
      "Epoch 13/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.4326 - val_accuracy: 0.8837\n",
      "Epoch 14/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 0.5606 - val_accuracy: 0.8918\n",
      "Epoch 15/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.5154 - val_accuracy: 0.8950\n",
      "Epoch 16/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0294 - accuracy: 0.9888 - val_loss: 0.6127 - val_accuracy: 0.8659\n",
      "Epoch 17/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0517 - accuracy: 0.9848 - val_loss: 0.5090 - val_accuracy: 0.8837\n",
      "Epoch 18/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.5111 - val_accuracy: 0.8950\n",
      "Epoch 19/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.6006 - val_accuracy: 0.8966\n",
      "Epoch 20/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.5999 - val_accuracy: 0.8821\n",
      "Epoch 21/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.5532 - val_accuracy: 0.9015\n",
      "Epoch 22/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.6159 - val_accuracy: 0.8708\n",
      "Epoch 23/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.6019 - val_accuracy: 0.8901\n",
      "Epoch 24/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.6491 - val_accuracy: 0.9015\n",
      "Epoch 25/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.6991 - val_accuracy: 0.9031\n",
      "Epoch 26/30\n",
      "174/174 [==============================] - 8s 46ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.6895 - val_accuracy: 0.8578\n",
      "Epoch 27/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0872 - accuracy: 0.9741 - val_loss: 0.4624 - val_accuracy: 0.8869\n",
      "Epoch 28/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.6114 - val_accuracy: 0.8901\n",
      "Epoch 29/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.6002 - val_accuracy: 0.9111\n",
      "Epoch 30/30\n",
      "174/174 [==============================] - 8s 45ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.6190 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "history = network_model.fit(X, Y, batch_size=32, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-grass",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
